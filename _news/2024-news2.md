---
title: >-
    New paper on Arxiv!
    <a href="https://arxiv.org/pdf/2411.17691" target="_blank">Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens <i class="fas fa-angle-double-right"></i></a>
date: 2024-11-26 10:00:00 EST
---