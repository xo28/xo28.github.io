---
title:          "Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens"
date:           2024-11-26 00:01:00 EST
selected:       true
# pub:            "International Conference on Machine Learning (ICML)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
# pub_date:       "2024"

# abstract: >-
#   Photo by Pineapple Supply Co. on Unsplash. Please put a tldr (too-long-didnt-read, 1~2 sentences) of your publication here. It is not recommended to put the actual abstract here because it is usually too long to fit in. $\LaTeX$ is supported. $a=b+c$.
# cover:          /assets/images/covers/cover3.jpg
authors:
  - Xu Ouyang
  - Tao Ge
  - Thomas Hartvigsen 
  - Zhisong Zhang 
  - Haitao Mi 
  - Dong Yu
links:
  Quantized checkpoints: https://huggingface.co/Xu-Ouyang
  # Unsplash: https://unsplash.com/photos/sliced-in-half-pineapple--_PLJZmHZzk
---
